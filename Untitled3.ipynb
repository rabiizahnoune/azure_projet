{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBQbNbtWUgSannGayCdiyX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabiizahnoune/azure_projet/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "u2fvwr_koIGT"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Cr√©er une session Spark\n",
        "spark = SparkSession.builder.appName(\"ColabPySpark\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.parquet(\"/content/green_tripdata_2022-01.parquet\")\n"
      ],
      "metadata": {
        "id": "iqIQMOOkoxQ9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnPzHu9Ao32u",
        "outputId": "3e2fafcc-2011-41e1-b2b8-589822ee6728"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
            "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
            "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
            "|       2| 2022-01-01 00:14:21|  2022-01-01 00:15:33|                 N|       1.0|          42|          42|            1.0|         0.44|        3.5|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         4.8|         2.0|      1.0|                 0.0|\n",
            "|       1| 2022-01-01 00:20:55|  2022-01-01 00:29:38|                 N|       1.0|         116|          41|            1.0|          2.1|        9.5|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|        10.8|         2.0|      1.0|                 0.0|\n",
            "|       1| 2022-01-01 00:57:02|  2022-01-01 01:13:14|                 N|       1.0|          41|         140|            1.0|          3.7|       14.5| 3.25|    0.5|       4.6|         0.0|     NULL|                  0.3|       23.15|         1.0|      1.0|                2.75|\n",
            "|       2| 2022-01-01 00:07:42|  2022-01-01 00:15:57|                 N|       1.0|         181|         181|            1.0|         1.69|        8.0|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         9.3|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:07:50|  2022-01-01 00:28:52|                 N|       1.0|          33|         170|            1.0|         6.26|       22.0|  0.5|    0.5|      5.21|         0.0|     NULL|                  0.3|       31.26|         1.0|      1.0|                2.75|\n",
            "|       1| 2022-01-01 00:47:57|  2022-01-01 00:54:09|                 N|       1.0|         150|         210|            1.0|          1.3|        7.0|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         8.3|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:13:38|  2022-01-01 00:33:50|                 N|       1.0|          66|          67|            1.0|         6.47|       22.5|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|        23.8|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:43:00|  2022-01-01 00:49:20|                 N|       1.0|          40|         195|            1.0|         1.15|        6.0|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         7.3|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:41:04|  2022-01-01 00:47:04|                 N|       1.0|         112|          80|            1.0|          1.3|        6.0|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         7.3|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:51:07|  2022-01-01 01:09:31|                 N|       1.0|         256|         186|            1.0|         4.75|       17.0|  0.5|    0.5|      4.21|         0.0|     NULL|                  0.3|       25.26|         1.0|      1.0|                2.75|\n",
            "|       2| 2021-12-31 23:44:03|  2021-12-31 23:57:25|                 N|       1.0|          75|           4|            1.0|         6.03|       18.5|  0.5|    0.5|       1.5|         0.0|     NULL|                  0.3|       24.05|         1.0|      1.0|                2.75|\n",
            "|       2| 2022-01-01 00:06:59|  2022-01-01 00:21:24|                 N|       1.0|          41|         116|            1.0|         2.82|       12.5|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|        13.8|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:47:35|  2022-01-01 00:50:20|                 N|       1.0|          75|          74|            1.0|          0.7|        4.5|  0.5|    0.5|      1.45|         0.0|     NULL|                  0.3|        7.25|         1.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:10:25|  2022-01-01 23:10:29|                 N|       1.0|          74|         260|            1.0|         5.48|       17.5|  0.5|    0.5|       0.0|        6.55|     NULL|                  0.3|       25.35|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:52:27|  2022-01-01 01:25:16|                 N|       1.0|          74|         231|            1.0|         7.54|       26.5|  0.5|    0.5|      6.11|         0.0|     NULL|                  0.3|       36.66|         1.0|      1.0|                2.75|\n",
            "|       1| 2022-01-01 00:47:31|  2022-01-01 00:49:51|                 N|       1.0|          74|          42|            1.0|          0.9|        4.5|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         5.8|         3.0|      1.0|                 0.0|\n",
            "|       1| 2022-01-01 00:59:10|  2022-01-01 01:21:02|                 N|       1.0|          41|          94|            1.0|          6.2|       21.5|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|        22.8|         1.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:12:00|  2022-01-01 00:26:26|                 N|       5.0|         213|         174|            1.0|         5.57|       20.0|  0.0|    0.0|       0.0|         0.0|     NULL|                  0.3|        20.3|         2.0|      2.0|                 0.0|\n",
            "|       2| 2022-01-01 00:47:15|  2022-01-01 00:53:07|                 N|       1.0|          51|         185|            1.0|         1.87|        7.0|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         8.3|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:54:40|  2022-01-01 01:17:02|                 N|       5.0|         185|         119|            1.0|          6.6|       25.0|  0.0|    0.0|       0.0|         0.0|     NULL|                  0.3|        25.3|         2.0|      2.0|                 0.0|\n",
            "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n"
      ],
      "metadata": {
        "id": "rnMtbJvNo51P"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M82WShCCqWKj",
        "outputId": "cd7d0159-5597-4ca8-b3c9-e68ee961f054"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- VendorID: long (nullable = true)\n",
            " |-- lpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
            " |-- lpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
            " |-- store_and_fwd_flag: string (nullable = true)\n",
            " |-- RatecodeID: double (nullable = true)\n",
            " |-- PULocationID: long (nullable = true)\n",
            " |-- DOLocationID: long (nullable = true)\n",
            " |-- passenger_count: double (nullable = true)\n",
            " |-- trip_distance: double (nullable = true)\n",
            " |-- fare_amount: double (nullable = true)\n",
            " |-- extra: double (nullable = true)\n",
            " |-- mta_tax: double (nullable = true)\n",
            " |-- tip_amount: double (nullable = true)\n",
            " |-- tolls_amount: double (nullable = true)\n",
            " |-- ehail_fee: integer (nullable = true)\n",
            " |-- improvement_surcharge: double (nullable = true)\n",
            " |-- total_amount: double (nullable = true)\n",
            " |-- payment_type: double (nullable = true)\n",
            " |-- trip_type: double (nullable = true)\n",
            " |-- congestion_surcharge: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[(col.name, col.dataType) for col in df.schema]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnKugQKapL1J",
        "outputId": "979faccb-552e-4306-8cec-48fbece46819"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('VendorID', LongType()),\n",
              " ('lpep_pickup_datetime', TimestampNTZType()),\n",
              " ('lpep_dropoff_datetime', TimestampNTZType()),\n",
              " ('store_and_fwd_flag', StringType()),\n",
              " ('RatecodeID', DoubleType()),\n",
              " ('PULocationID', LongType()),\n",
              " ('DOLocationID', LongType()),\n",
              " ('passenger_count', DoubleType()),\n",
              " ('trip_distance', DoubleType()),\n",
              " ('fare_amount', DoubleType()),\n",
              " ('extra', DoubleType()),\n",
              " ('mta_tax', DoubleType()),\n",
              " ('tip_amount', DoubleType()),\n",
              " ('tolls_amount', DoubleType()),\n",
              " ('ehail_fee', IntegerType()),\n",
              " ('improvement_surcharge', DoubleType()),\n",
              " ('total_amount', DoubleType()),\n",
              " ('payment_type', DoubleType()),\n",
              " ('trip_type', DoubleType()),\n",
              " ('congestion_surcharge', DoubleType())]"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#changer le typde de colone date\n",
        "df = df.withColumn(\"lpep_pickup_datetime\", col(\"lpep_pickup_datetime\").cast(\"timestamp\"))\n"
      ],
      "metadata": {
        "id": "1tMRajHrprBK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import min, max\n",
        "\n",
        "# R√©cup√©rer les dates min et max\n",
        "min_max_dates = df.select(\n",
        "    min(\"lpep_pickup_datetime\").alias(\"min_date\"),\n",
        "    max(\"lpep_pickup_datetime\").alias(\"max_date\")\n",
        ").collect()\n",
        "\n",
        "min_date = min_max_dates[0][\"min_date\"]\n",
        "max_date = min_max_dates[0][\"max_date\"]\n",
        "\n",
        "print(f\"üìÖ Plage de dates : {min_date} ‚ûù {max_date}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_smw45QsDvj",
        "outputId": "26714b1a-39dc-418b-b9e2-1daa95d9070b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Plage de dates : 2009-01-01 00:34:01 ‚ûù 2022-01-31 23:57:37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year\n",
        "\n",
        "# Filtrer les lignes o√π l'ann√©e est diff√©rente de 2022\n",
        "df_not_2022 = df.filter(year(\"lpep_pickup_datetime\") != 2022)\n",
        "\n",
        "# Compter ces lignes\n",
        "count_not_2022 = df_not_2022.count()\n",
        "\n",
        "print(f\"üìä Nombre de lignes o√π la date n'est pas en 2022 : {count_not_2022}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3lok4vksKG0",
        "outputId": "2a911033-85b4-4fcd-dd6f-ceef4182400d"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Nombre de lignes o√π la date n'est pas en 2022 : 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, year, month, dayofmonth, to_date, lit,when,lpad,concat\n",
        "\n",
        "# Remplacer l'ann√©e par 2022 tout en gardant le mois et le jour\n",
        "df = df.withColumn(\n",
        "    \"lpep_pickup_datetime\",\n",
        "    when(year(col(\"lpep_pickup_datetime\")) != 2022,\n",
        "         to_date(\n",
        "             concat(lit(\"2022-\"),\n",
        "                    lpad(month(col(\"lpep_pickup_datetime\")).cast(\"string\"), 2, \"0\"),\n",
        "                    lit(\"-\"),\n",
        "                    lpad(dayofmonth(col(\"lpep_pickup_datetime\")).cast(\"string\"), 2, \"0\")),\n",
        "             \"yyyy-MM-dd\")\n",
        "    ).otherwise(col(\"lpep_pickup_datetime\"))\n",
        ")\n",
        "\n",
        "# V√©rifier les premi√®res lignes pour s'assurer du changement\n",
        "df.show(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PudEahFzFYY",
        "outputId": "5845fa49-e9bc-422c-d234-e52e2742d477"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
            "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
            "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
            "|       2| 2022-01-01 00:14:21|  2022-01-01 00:15:33|                 N|       1.0|          42|          42|            1.0|         0.44|        3.5|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         4.8|         2.0|      1.0|                 0.0|\n",
            "|       1| 2022-01-01 00:20:55|  2022-01-01 00:29:38|                 N|       1.0|         116|          41|            1.0|          2.1|        9.5|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|        10.8|         2.0|      1.0|                 0.0|\n",
            "|       1| 2022-01-01 00:57:02|  2022-01-01 01:13:14|                 N|       1.0|          41|         140|            1.0|          3.7|       14.5| 3.25|    0.5|       4.6|         0.0|     NULL|                  0.3|       23.15|         1.0|      1.0|                2.75|\n",
            "|       2| 2022-01-01 00:07:42|  2022-01-01 00:15:57|                 N|       1.0|         181|         181|            1.0|         1.69|        8.0|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         9.3|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:07:50|  2022-01-01 00:28:52|                 N|       1.0|          33|         170|            1.0|         6.26|       22.0|  0.5|    0.5|      5.21|         0.0|     NULL|                  0.3|       31.26|         1.0|      1.0|                2.75|\n",
            "|       1| 2022-01-01 00:47:57|  2022-01-01 00:54:09|                 N|       1.0|         150|         210|            1.0|          1.3|        7.0|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         8.3|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:13:38|  2022-01-01 00:33:50|                 N|       1.0|          66|          67|            1.0|         6.47|       22.5|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|        23.8|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:43:00|  2022-01-01 00:49:20|                 N|       1.0|          40|         195|            1.0|         1.15|        6.0|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         7.3|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:41:04|  2022-01-01 00:47:04|                 N|       1.0|         112|          80|            1.0|          1.3|        6.0|  0.5|    0.5|       0.0|         0.0|     NULL|                  0.3|         7.3|         2.0|      1.0|                 0.0|\n",
            "|       2| 2022-01-01 00:51:07|  2022-01-01 01:09:31|                 N|       1.0|         256|         186|            1.0|         4.75|       17.0|  0.5|    0.5|      4.21|         0.0|     NULL|                  0.3|       25.26|         1.0|      1.0|                2.75|\n",
            "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checker outliers de date = 2019\n",
        "from pyspark.sql.functions import year\n",
        "\n",
        "# Filtrer les lignes o√π l'ann√©e est diff√©rente de 2022\n",
        "df_not_2022 = df.filter(year(\"lpep_pickup_datetime\") != 2022)\n",
        "\n",
        "# Compter ces lignes\n",
        "count_not_2022 = df_not_2022.count()\n",
        "\n",
        "print(f\"üìä Nombre de lignes o√π la date n'est pas en 2022 : {count_not_2022}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDiFwUv0XR9W",
        "outputId": "00c29e5f-a75e-4118-c050-56b519ccfdb1"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Nombre de lignes o√π la date n'est pas en 2022 : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#voir plage de dates\n",
        "from pyspark.sql.functions import min, max\n",
        "\n",
        "# R√©cup√©rer les dates min et max\n",
        "min_max_dates = df.select(\n",
        "    min(\"lpep_pickup_datetime\").alias(\"min_date\"),\n",
        "    max(\"lpep_pickup_datetime\").alias(\"max_date\")\n",
        ").collect()\n",
        "\n",
        "min_date = min_max_dates[0][\"min_date\"]\n",
        "max_date = min_max_dates[0][\"max_date\"]\n",
        "\n",
        "print(f\"üìÖ Plage de dates : {min_date} ‚ûù {max_date}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FutlNSnxYG1s",
        "outputId": "1012c238-f813-4b2c-9232-8cf4ba5b6e04"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÖ Plage de dates : 2022-01-01 00:00:00 ‚ûù 2022-12-31 00:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***creation d un table dim_Date_depart***"
      ],
      "metadata": {
        "id": "CNPkMR1caeYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# G√©n√©rer l'ID unique bas√© sur la date et l'heure\n",
        "\n",
        "from pyspark.sql.functions import col, year, month, dayofmonth, hour, minute, second, concat, lpad, lit\n",
        "df = df.withColumn(\n",
        "    \"idda_te\",\n",
        "    concat(\n",
        "        year(col(\"lpep_pickup_datetime\")),\n",
        "        lpad(month(col(\"lpep_pickup_datetime\")).cast(\"string\"), 2, \"0\"),\n",
        "        lpad(dayofmonth(col(\"lpep_pickup_datetime\")).cast(\"string\"), 2, \"0\"),\n",
        "        lpad(hour(col(\"lpep_pickup_datetime\")).cast(\"string\"), 2, \"0\"),\n",
        "        lpad(minute(col(\"lpep_pickup_datetime\")).cast(\"string\"), 2, \"0\"),\n",
        "        lpad(second(col(\"lpep_pickup_datetime\")).cast(\"string\"), 2, \"0\")\n",
        "    )\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "lZTyiV0TYPB2"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construire la table de dimension date (dim_date)\n",
        "df_dim_date_depart = df.select(\n",
        "    \"idda_te\",  # Identifiant unique\n",
        "    year(col(\"lpep_pickup_datetime\")).alias(\"year\"),\n",
        "    month(col(\"lpep_pickup_datetime\")).alias(\"month\"),\n",
        "    dayofmonth(col(\"lpep_pickup_datetime\")).alias(\"day\"),\n",
        "    hour(col(\"lpep_pickup_datetime\")).alias(\"hour\"),\n",
        "    minute(col(\"lpep_pickup_datetime\")).alias(\"minute\"),\n",
        "    second(col(\"lpep_pickup_datetime\")).alias(\"second\"),\n",
        "    \"lpep_pickup_datetime\"  # Ajouter la colonne de date-heure originale\n",
        ")\n",
        "\n",
        "# Afficher les premi√®res lignes pour v√©rifier\n",
        "df_dim_date_depart.show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyBs0nnManwC",
        "outputId": "2c96ea0d-52a4-4abe-819a-8feb0864bf96"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+-----+---+----+------+------+--------------------+\n",
            "|idda_te       |year|month|day|hour|minute|second|lpep_pickup_datetime|\n",
            "+--------------+----+-----+---+----+------+------+--------------------+\n",
            "|20220101001421|2022|1    |1  |0   |14    |21    |2022-01-01 00:14:21 |\n",
            "|20220101002055|2022|1    |1  |0   |20    |55    |2022-01-01 00:20:55 |\n",
            "|20220101005702|2022|1    |1  |0   |57    |2     |2022-01-01 00:57:02 |\n",
            "|20220101000742|2022|1    |1  |0   |7     |42    |2022-01-01 00:07:42 |\n",
            "|20220101000750|2022|1    |1  |0   |7     |50    |2022-01-01 00:07:50 |\n",
            "|20220101004757|2022|1    |1  |0   |47    |57    |2022-01-01 00:47:57 |\n",
            "|20220101001338|2022|1    |1  |0   |13    |38    |2022-01-01 00:13:38 |\n",
            "|20220101004300|2022|1    |1  |0   |43    |0     |2022-01-01 00:43:00 |\n",
            "|20220101004104|2022|1    |1  |0   |41    |4     |2022-01-01 00:41:04 |\n",
            "|20220101005107|2022|1    |1  |0   |51    |7     |2022-01-01 00:51:07 |\n",
            "+--------------+----+-----+---+----+------+------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***creation de table de dimension dim_date_finale***"
      ],
      "metadata": {
        "id": "w6Ln0dGkt23p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year\n",
        "\n",
        "# Filtrer les lignes o√π l'ann√©e est diff√©rente de 2022\n",
        "df_not_2022 = df.filter(year(\"lpep_dropoff_datetime\") != 2022)\n",
        "\n",
        "# Compter ces lignes\n",
        "count_not_2022 = df_not_2022.count()\n",
        "\n",
        "print(f\"üìä Nombre de lignes o√π la date n'est pas en 2022 : {count_not_2022}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtL-AROFuL4c",
        "outputId": "7b5c3254-fad3-4a2a-b37a-a3a9444cabb4"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Nombre de lignes o√π la date n'est pas en 2022 : 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, year, month, dayofmonth, to_date, lit,when,lpad,concat\n",
        "\n",
        "# Remplacer l'ann√©e par 2022 tout en gardant le mois et le jour\n",
        "df = df.withColumn(\n",
        "    \"lpep_dropoff_datetime\",\n",
        "    when(year(col(\"lpep_dropoff_datetime\")) != 2022,\n",
        "         to_date(\n",
        "             concat(lit(\"2022-\"),\n",
        "                    lpad(month(col(\"lpep_dropoff_datetime\")).cast(\"string\"), 2, \"0\"),\n",
        "                    lit(\"-\"),\n",
        "                    lpad(dayofmonth(col(\"lpep_dropoff_datetime\")).cast(\"string\"), 2, \"0\")),\n",
        "             \"yyyy-MM-dd\")\n",
        "    ).otherwise(col(\"lpep_dropoff_datetime\"))\n",
        ")\n",
        "\n",
        "# V√©rifier les premi√®res lignes pour s'assurer du changement\n",
        "\n",
        "from pyspark.sql.functions import year\n",
        "\n",
        "# Filtrer les lignes o√π l'ann√©e est diff√©rente de 2022\n",
        "df_not_2022 = df.filter(year(\"lpep_dropoff_datetime\") != 2022)\n",
        "\n",
        "# Compter ces lignes\n",
        "count_not_2022 = df_not_2022.count()\n",
        "\n",
        "print(f\"üìä Nombre de lignes o√π la date n'est pas en 2022 : {count_not_2022}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUGsoKtDuZey",
        "outputId": "59a1aa26-9551-4e41-eb9f-e17528334383"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Nombre de lignes o√π la date n'est pas en 2022 : 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# G√©n√©rer l'ID unique bas√© sur la date et l'heure\n",
        "\n",
        "from pyspark.sql.functions import col, year, month, dayofmonth, hour, minute, second, concat, lpad, lit\n",
        "df = df.withColumn(\n",
        "    \"id_date_finale\",\n",
        "    concat(\n",
        "        year(col(\"lpep_dropoff_datetime\")),\n",
        "        lpad(month(col(\"lpep_dropoff_datetime\")).cast(\"string\"), 2, \"0\"),\n",
        "        lpad(dayofmonth(col(\"lpep_dropoff_datetime\")).cast(\"string\"), 2, \"0\"),\n",
        "        lpad(hour(col(\"lpep_dropoff_datetime\")).cast(\"string\"), 2, \"0\"),\n",
        "        lpad(minute(col(\"lpep_dropoff_datetime\")).cast(\"string\"), 2, \"0\"),\n",
        "        lpad(second(col(\"lpep_dropoff_datetime\")).cast(\"string\"), 2, \"0\")\n",
        "    )\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "1qp1FVJ-p5Bs"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Construire la table de dimension date (dim_date)\n",
        "df_dim_date_finale = df.select(\n",
        "    \"idda_te\",  # Identifiant unique\n",
        "    year(col(\"lpep_pickup_datetime\")).alias(\"year\"),\n",
        "    month(col(\"lpep_pickup_datetime\")).alias(\"month\"),\n",
        "    dayofmonth(col(\"lpep_pickup_datetime\")).alias(\"day\"),\n",
        "    hour(col(\"lpep_pickup_datetime\")).alias(\"hour\"),\n",
        "    minute(col(\"lpep_pickup_datetime\")).alias(\"minute\"),\n",
        "    second(col(\"lpep_pickup_datetime\")).alias(\"second\"),\n",
        "    \"lpep_pickup_datetime\"  # Ajouter la colonne de date-heure originale\n",
        ")\n",
        "\n",
        "# Afficher les premi√®res lignes pour v√©rifier\n",
        "df_dim_date_finale.show(10, truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RTdtAQ-umcy",
        "outputId": "afdd96af-e8f8-470b-c08a-e6d9bc6a4fca"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+----+-----+---+----+------+------+--------------------+\n",
            "|idda_te       |year|month|day|hour|minute|second|lpep_pickup_datetime|\n",
            "+--------------+----+-----+---+----+------+------+--------------------+\n",
            "|20220101001421|2022|1    |1  |0   |14    |21    |2022-01-01 00:14:21 |\n",
            "|20220101002055|2022|1    |1  |0   |20    |55    |2022-01-01 00:20:55 |\n",
            "|20220101005702|2022|1    |1  |0   |57    |2     |2022-01-01 00:57:02 |\n",
            "|20220101000742|2022|1    |1  |0   |7     |42    |2022-01-01 00:07:42 |\n",
            "|20220101000750|2022|1    |1  |0   |7     |50    |2022-01-01 00:07:50 |\n",
            "|20220101004757|2022|1    |1  |0   |47    |57    |2022-01-01 00:47:57 |\n",
            "|20220101001338|2022|1    |1  |0   |13    |38    |2022-01-01 00:13:38 |\n",
            "|20220101004300|2022|1    |1  |0   |43    |0     |2022-01-01 00:43:00 |\n",
            "|20220101004104|2022|1    |1  |0   |41    |4     |2022-01-01 00:41:04 |\n",
            "|20220101005107|2022|1    |1  |0   |51    |7     |2022-01-01 00:51:07 |\n",
            "+--------------+----+-----+---+----+------+------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***table Dim_payment***"
      ],
      "metadata": {
        "id": "N0i5x8o7oRuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"payment_type\").distinct().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSUm2KfxsuC0",
        "outputId": "994f9452-8c3e-4f75-894a-d56ce81d0776"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+\n",
            "|payment_type|\n",
            "+------------+\n",
            "|         1.0|\n",
            "|         4.0|\n",
            "|        NULL|\n",
            "|         3.0|\n",
            "|         2.0|\n",
            "|         5.0|\n",
            "+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cr√©er la table de dimension type_payment\n",
        "data_type_payment = [\n",
        "    (1, \"credit_card\"),\n",
        "    (2, \"cash\"),\n",
        "    (3, \"no_charge\"),\n",
        "    (4, \"dispute\"),\n",
        "    (5, \"unknown\"),\n",
        "    (6, \"voided_trip\")\n",
        "]\n",
        "\n",
        "# Colonnes : id_payment (identifiant) et type_payment (libell√©)\n",
        "columns = [\"id_payment\", \"type_payment\"]\n",
        "\n",
        "# Cr√©er un DataFrame PySpark pour la table de dimension\n",
        "df_type_payment = spark.createDataFrame(data_type_payment, columns)\n",
        "\n",
        "# Afficher la table de dimension type_payment\n",
        "df_type_payment.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GUSRlC93arBY",
        "outputId": "45b9aa69-9274-4a06-f4a0-8a70ee4ffda8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+\n",
            "|id_payment|type_payment|\n",
            "+----------+------------+\n",
            "|         1| credit_card|\n",
            "|         2|        cash|\n",
            "|         3|   no_charge|\n",
            "|         4|     dispute|\n",
            "|         5|     unknown|\n",
            "|         6| voided_trip|\n",
            "+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.select('trip_type').distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX9uso1rs6aC",
        "outputId": "e9c95bd4-a895-4943-8df5-261f5c3439cf"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+\n",
            "|trip_type|\n",
            "+---------+\n",
            "|      1.0|\n",
            "|      2.0|\n",
            "|     NULL|\n",
            "+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creer la table de dimension type_trip\n",
        "data_type_trip = [\n",
        "    (1, \"Street-hail\"),\n",
        "    (2, \"Dispatch\"),\n",
        "    (3, \"Unknown\")\n",
        "]\n",
        "\n",
        "columns = ['id_trip', 'type_trip']\n",
        "\n",
        "df_type_trip = spark.createDataFrame(data_type_trip, columns)\n",
        "\n",
        "df_type_trip.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3wchNNFqQRk",
        "outputId": "671b1096-3ee3-4c4d-dabc-679c9ded7167"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+\n",
            "|id_trip|  type_trip|\n",
            "+-------+-----------+\n",
            "|      1|Street-hail|\n",
            "|      2|   Dispatch|\n",
            "|      3|    Unknown|\n",
            "+-------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***creation de la table de fait ***"
      ],
      "metadata": {
        "id": "jdHuwEGMv4yk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1d16kxgkv3-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1W9MtgsMtW6O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}